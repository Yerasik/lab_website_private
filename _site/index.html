<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
<meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="The UBD Ajaz Ahmad Bhat's lab is a multidisciplinary research hub focused on exploring the frontiers of artificial intelligence through the lens of human cognition and behavior. We build autonomous systems that think, reason, and adapt in ways that mirror—and often surpass—human intelligence.">
<title>Laboratory</title>
<link rel="canonical" href="http://localhost:4000/">
<link rel="icon" type="image/x-icon" href="/lab_website_private/favicon.ico">
<link rel="shortcut icon" type="image/x-icon" href="/lab_website_private/favicon.ico">
<link rel="stylesheet" type="text/css" href="/lab_website_private/assets/css/styles.css">
    </head>
    <body>
        <!-- Navigation -->
<div class="background"> </div>
<nav class="nav-wrap">
    <a href="/lab_website_private/" class="nav-logo">
    <?xml version="1.0" encoding="utf-8"?>
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
     viewBox="0 0 403 230" style="enable-background:new 0 0 403 230;" xml:space="preserve">
  <g>
    <text x="50" y="150" font-family="Arial" font-size="100">LAB</text>
  </g>
</svg>
  </a>
  <ul class="navigation">
    <li><a href="/lab_website_private/">Home</a></li>
    <li><a href="/lab_website_private/team">Team</a></li>
    <li><a href="/lab_website_private/publications">Publications</a></li>
    <li><a href="/lab_website_private/projects">Projects</a></li>
    <li><a href="/lab_website_private/news">News</a></li>
    <li><a href="/lab_website_private/contact-us">Contact Us</a></li>
  </ul>
  <!-- Mobile Navigation -->
  <div class="nav-toggle-open-wrapper toggle-dark">
    <?xml version="1.0" encoding="utf-8"?>
    <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
    <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="24px" height="18px" viewBox="0 0 24 18" enable-background="new 0 0 24 18" xml:space="preserve">
      <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0" y1="9" x2="24" y2="9"/>
      <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0" y1="1" x2="24" y2="1"/>
      <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0" y1="17" x2="24" y2="17"/>
    </svg>
  </div>
  <div class="nav-toggle-body-overlay"></div>
    <div class="toggled-nav-wrapper">
      <div class="nav-toggle-close-wrapper">
        <?xml version="1.0" encoding="utf-8"?>
        <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="18.385px" height="18.385px" viewBox="0 0 18.385 18.385" enable-background="new 0 0 18.385 18.385" xml:space="preserve">
          <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0.707" y1="17.678" x2="17.678" y2="0.707"/>
          <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0.707" y1="0.707" x2="17.678" y2="17.678"/>
        </svg>
      </div>
      <div class="internal-nav-links-wrapper">
        <a href="/lab_website_private/" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Home</h5></div><div class="internal-link-icon internal-link-icon-home"></div></a>
        <a href="/lab_website_private/team" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Team</h5></div><div class="internal-link-icon internal-link-icon-team"></div></a>
        <a href="/lab_website_private/publications" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Publications</h5></div><div class="internal-link-icon internal-link-icon-publications"></div></a>
        <a href="/lab_website_private/projects" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Projects</h5></div><div class="internal-link-icon internal-link-icon-research"></div></a>
        <a href="/lab_website_private/news" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>News</h5></div><div class="internal-link-icon internal-link-icon-news"></div></a>
        <a href="/lab_website_private/contact-us" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Contact Us</h5></div><div class="internal-link-icon internal-link-icon-contact-us"></div></a>
      </div>
      <hr/>
      <div class="external-links-wrapper">
        <a href="https://scholar.google.com/citations?user=9PX9YjUAAAAJ&hl=en" target="_blank" class="external-link-wrapper"><h6>Google Scholar</h6><div class="external-link-icon external-link-icon-googlescholar"></div></a>
        <a href="mailto:ajaz.bhat@ubd.edu.bn" target="_blank" class="external-link-wrapper"><h6>Email</h6><div class="external-link-icon external-link-icon-email"></div></a>
        <a href="https://www.youtube.com/channel/UCbTav7pqgfIFCoH_ccnXPMw" target="_blank" class="external-link-wrapper"><h6>Youtube</h6><div class="external-link-icon external-link-icon-youtube"></div></a>
      </div>
    </div>
  
</nav>
<!-- End Navigation -->
<!-- first container -->
<div class="container-1">
    <div class="slider">
        
        
        <div id="slide-1" class="slide">
            <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Knowledge Graphs & AI Recommendations">
            <div class="slide-text">
                <h1><a href="project/project1">Knowledge Graphs & AI Recommendations</a></h1>
                <p>Developed models for predicting missing graph links, applied to drug discovery, recommendation systems, and HR. Published at ACL, NeurIPS, ICML.</p>
            </div>
        </div>
        
        <div id="slide-2" class="slide">
            <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Memory-Driven Reasoning in Robots">
            <div class="slide-text">
                <h1><a href="project/project2">Memory-Driven Reasoning in Robots</a></h1>
                <p>Robots simulate past experiences to solve new problems creatively. Used in experiments and industrial multi-robot setups.</p>
            </div>
        </div>
        
        <div id="slide-3" class="slide">
            <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Motor Intelligence & Body Schema">
            <div class="slide-text">
                <h1><a href="project/project3">Motor Intelligence & Body Schema</a></h1>
                <p>Robots abstract cause-effect relations from experience, enabling intuitive actions with unseen objects. Featured in Royal Society & BBC.</p>
            </div>
        </div>
        
        <div id="slide-4" class="slide">
            <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Motor Intelligence & Body Schema">
            <div class="slide-text">
                <h1><a href="project/project4">Motor Intelligence & Body Schema</a></h1>
                <p>Neural models improve dexterity and tool use in complex tasks. Applied to iCub and industrial robots for fast, adaptable motion.</p>
            </div>
        </div>
        
        <div id="slide-5" class="slide">
            <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Spatial Planning & Multi-Robot Collaboration">
            <div class="slide-text">
                <h1><a href="project/project5">Spatial Planning & Multi-Robot Collaboration</a></h1>
                <p>Robots coordinate in shared spaces through dynamic planning and task negotiation. Enables scalable teamwork in real-world assembly.</p>
            </div>
        </div>
        
        <div id="slide-6" class="slide">
            <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Language & Visual Exploration in Infants">
            <div class="slide-text">
                <h1><a href="project/project6">Language & Visual Exploration in Infants</a></h1>
                <p>Model explains how babies learn language through visual exploration. Matches patterns across developmental studies.</p>
            </div>
        </div>
        
        <div id="slide-7" class="slide">
            <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Word Learning Experiments Across Ages">
            <div class="slide-text">
                <h1><a href="project/project7">Word Learning Experiments Across Ages</a></h1>
                <p>Studies show children’s attention patterns differ from adults. Challenges standard testing and supports new learning models.</p>
            </div>
        </div>
        
    </div>
    
    <div>
         <button class="arrow left-arrow">&#10094;</button> <!-- Left arrow -->
         <button class="arrow right-arrow">&#10095;</button> <!-- Right arrow -->
    </div>

    <div>
        <a  href="#container-news"class="int-arrows-body">
            <div class="int-arrow"></div>
            <div class="int-arrow"></div>
        </a>
    </div>
    
    
</div>



<script>
  const slider = document.querySelector('.slider');
  const slides = document.querySelectorAll('.slide');
  const leftArrow = document.querySelector('.left-arrow');
  const rightArrow = document.querySelector('.right-arrow');
  let index = 0;
  let interval;

  function goToSlide(i) {
    index = (i + slides.length) % slides.length; // wrap around
    slider.scrollTo({
      left: slides[index].offsetLeft,
      behavior: 'smooth'
    });
    resetInterval();
  }

  function resetInterval() {
    clearInterval(interval);
    interval = setInterval(() => {
      index = (index + 1) % slides.length;
      slider.scrollTo({
        left: slides[index].offsetLeft,
        behavior: 'smooth'
      });
    }, 5000);
  }

  leftArrow.addEventListener('click', () => goToSlide(index - 1));
  rightArrow.addEventListener('click', () => goToSlide(index + 1));
  // Start the interval
  resetInterval();
</script>

<div id="container-news" class="container-news">
  <div class="header-wrapper">
    <h1 class="header">News</h1>
  </div>
  <div class="scroller-news">
    <div class="news-content-wrapper" >
    
      <div class="news-wrapper" data-href=" somelink ">
        <div class="text-wrapper">
          <div class="date">
            <p> 18.07.2025 </p>       
            <hr>
          </div>
          <p> text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.
 </p>
        </div>
      </div>
    
      <div class="news-wrapper" data-href=" somelink ">
        <div class="text-wrapper">
          <div class="date">
            <p> 18.07.2025 </p>       
            <hr>
          </div>
          <p> text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.
 </p>
        </div>
      </div>
    
      <div class="news-wrapper" data-href=" somelink ">
        <div class="text-wrapper">
          <div class="date">
            <p> 18.07.2025 </p>       
            <hr>
          </div>
          <p> text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.
 </p>
        </div>
      </div>
    
      <div class="news-wrapper" data-href=" somelink ">
        <div class="text-wrapper">
          <div class="date">
            <p> 18.07.2025 </p>       
            <hr>
          </div>
          <p> text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.
 </p>
        </div>
      </div>
    
      <div class="news-wrapper" data-href=" somelink ">
        <div class="text-wrapper">
          <div class="date">
            <p> 18.07.2025 </p>       
            <hr>
          </div>
          <p> text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.
 </p>
        </div>
      </div>
    
      <div class="news-wrapper" data-href=" somelink ">
        <div class="text-wrapper">
          <div class="date">
            <p> 18.07.2025 </p>       
            <hr>
          </div>
          <p> text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.
 </p>
        </div>
      </div>
    
      <div class="news-wrapper" data-href=" somelink ">
        <div class="text-wrapper">
          <div class="date">
            <p> 18.07.2025 </p>       
            <hr>
          </div>
          <p> text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.text.
 </p>
        </div>
      </div>
    
  </div>
  
  </div>
  <div>
    <a  href="#container-3"class="int-arrows-body">
        <div class="int-arrow"></div>
        <div class="int-arrow"></div>
    </a>
  </div>
</div>

<script>

document.querySelectorAll('.news-wrapper').forEach(el => {
  el.addEventListener('click', () => {
    const url = el.dataset.href;
    if (url) window.location.href = url;
  });
});

</script>
<!-- second container -->
<div id="container-3" class="container-3">
  <h1 class="header">Publications</h1>
<div class="scroller">
  <div class="publications-content-wrapper">
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Learning with a network of Competing Synapses</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Learning with a network of Competing Synapses">
        </div>

        <p>Competition between synapses arises in correlation-based plasticity. We propose a game-theory-inspired model in which synapses switch between weak and strong states, driven by local competition and memory of past outcomes. The framework reproduces power-law forgetting and captures motor adaptation phenomena like savings and rebound via distinct timescales.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication1">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Dynamics of Competitive Learning: The Role of Updates and Memory</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Dynamics of Competitive Learning: The Role of Updates and Memory">
        </div>

        <p>We analyze how parallel versus sequential updating and synaptic memory affect phases of consensus and polarization in a competitive learning model. The phase diagram exhibits ordered and disordered regimes, with critical exponents matching the voter model universality class.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication2">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>“Connecting Experiences”: Towards a Biologically Inspired Episodic Memory for Developmental Robots</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="“Connecting Experiences”: Towards a Biologically Inspired Episodic Memory for Developmental Robots">
        </div>

        <p>Robots must flexibly connect context-relevant chunks of past experience to meet novel goals. We introduce a neural framework that encodes high-dimensional sensorimotor episodes into structured episodic memory and retrieves relevant sequences to simulate unexperienced actions.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication3">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>From Object-Action to Property-Action: Learning Causally Dominant Properties through Cumulative Explorative Interactions</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="From Object-Action to Property-Action: Learning Causally Dominant Properties through Cumulative Explorative Interactions">
        </div>

        <p>We explore how robots can discover which object properties drive task outcomes by cumulatively interacting with objects varying along multiple dimensions. Through a dynamic neural field model, robots infer causally dominant properties from exploration data without supervision.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication4">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>How iCub Learns to Imitate Use of a Tool Quickly by Recycling the Past Knowledge Learnt During Drawing</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="How iCub Learns to Imitate Use of a Tool Quickly by Recycling the Past Knowledge Learnt During Drawing">
        </div>

        <p>We show that the iCub humanoid can generalize motor skills by representing movements as shape primitives. After learning to draw shapes, the robot rapidly adapts to tool use tasks by recombining existing shape modules rather than learning from scratch.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication5">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Humanoid Robot Infers Archimedes' Principle: From Cumulative Exploration to Abstraction of Underlying Physical Relations and Object Affordances</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Humanoid Robot Infers Archimedes' Principle: From Cumulative Exploration to Abstraction of Underlying Physical Relations and Object Affordances">
        </div>

        <p>Reenacting Aesop's Crow and Pitcher on a humanoid, we propose a neural architecture that encodes sensorimotor interactions into episodic traces and applies four learning rules (elimination, growth, uncertainty, status quo) to extract causal relations. The robot's predictions for novel objects converge to Archimedes' law.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication6">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Towards a Learnt Neural Body Schema for Dexterous Coordination of Action in Humanoid and Industrial Robots</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Towards a Learnt Neural Body Schema for Dexterous Coordination of Action in Humanoid and Industrial Robots">
        </div>

        <p>We describe a neural framework that learns a distributed body schema enabling simultaneous control of multiple limbs or tools. Forward simulations inform real-time motor plans, resolving redundancy by well-posed field computations rather than inverse kinematics.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication7">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>A Dynamic Neural Field Model of Memory, Attention and Cross-Situational Word Learning</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="A Dynamic Neural Field Model of Memory, Attention and Cross-Situational Word Learning">
        </div>

        <p>WOLVES integrates dynamic neural fields for vision and language to model cross-situational word learning. Peaks represent sustained attention to objects and words; memory fields accumulate co-occurrence statistics. The model reproduces human looking and learning curves across 12 experiments.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication8">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Joint Goal Human-Robot Collaboration—From Remembering to Inferring</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Joint Goal Human-Robot Collaboration—From Remembering to Inferring">
        </div>

        <p>We present a bio-inspired neural architecture where two robots learn internal models of their bodies and peripersonal space. Coupled simulations allow anticipation of partner actions and dynamic task allocation, enabling cooperative assembly of fuse-boxes in unstructured environments.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication9">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Goal-Directed Reasoning and Cooperation in Robots in Shared Workspaces: An Internal Simulation-Based Neural Framework</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Goal-Directed Reasoning and Cooperation in Robots in Shared Workspaces: An Internal Simulation-Based Neural Framework">
        </div>

        <p>In an industrial assembly task, two robots share workspace to assemble fuse-boxes. We describe coupled forward models of body and peripersonal space learned via exploration. Internal simulation evaluates action-consequence pairs, driving cooperative sequences even when solo goals are unachievable.</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication10">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Muscle-less motor synergies and actions without movements. From motor neuroscience to cognitive robotics</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Muscle-less motor synergies and actions without movements. From motor neuroscience to cognitive robotics">
        </div>

        <p>Emerging trends in neurosciences provide converging evidence that cortical networks in predominantly motor areas are activated in multiple contexts related to “action” that do not cause overt movement. For complex bodies—human or embodied robots—there must be a seamless alternation between shaping motor output during action execution and simulating potential actions for feasibility and understanding. Revisiting the Equilibrium Point Hypothesis and muscle‐synergy formation, this article proposes a “plastic, configurable” internal body‐schema as a unifying principle enabling both real and imagined actions through internal simulation. The theoretical rationale is grounded in intracranial recordings, fMRI studies of action execution/imagination, tool‐use experiments, and computational robot models to show how muscleless motor synergies arise from goal‐directed body‐schema animation.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication11">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>The complementarity of ‘Muscleless’ motor synergies with motor control strategies in humans and robots: Reply to Comments</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="The complementarity of ‘Muscleless’ motor synergies with motor control strategies in humans and robots: Reply to Comments">
        </div>

        <p>No abstract provided.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication12">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Causal Learning by a Robot with Semantic-Episodic Memory in an Aesop's Fable Experiment</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Causal Learning by a Robot with Semantic-Episodic Memory in an Aesop's Fable Experiment">
        </div>

        <p>Corvids, apes, and children solve the Crow and the Pitcher task, indicating causal understanding. To explore how agents abstract cause–effect relations from cumulative interactions, we re-enact the task on a robot equipped with a brain-guided neural model of semantic-episodic memory. Four task-agnostic learning rules compare expectations recalled from past episodes with current scenarios to extract hidden causal relations. Robot behaviors illustrate causal learning, and predictions for novel objects converge to Archimedes’ principle, independent of exploration order and object set.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication13">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Effect of Metric Variation in Object Shapes and Colours on Cross-Situational Word Learning in Adults</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Effect of Metric Variation in Object Shapes and Colours on Cross-Situational Word Learning in Adults">
        </div>

        <p>Cross-situational word learning (CSWL) requires tracking word–object co-occurrence across ambiguous naming scenarios to infer correct mappings. Prior work shows eye movements reflect learning success but may be influenced by object properties. This experiment will systematically vary object shape and colour distances on each trial—‘Near’ (similar) versus ‘Far’ (distinct)—while controlling stimulus pairs. Eye-tracking and forced-choice naming tests will assess how metric variation affects real-time attention and word‐learning accuracy.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication14">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Moving beyond Associative Learning and Hypothesis Testing: How Stimulus Exposure Times and Looking Behaviours Conspire in Cross-Situational Word Learning</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Moving beyond Associative Learning and Hypothesis Testing: How Stimulus Exposure Times and Looking Behaviours Conspire in Cross-Situational Word Learning">
        </div>

        <p>This pre‐registered study investigates how the duration of stimulus exposure and participants’ looking behaviours jointly influence cross‐situational word learning. By manipulating exposure times and recording eye movements, we will examine contributions of associative learning versus hypothesis‐testing mechanisms across multiple ambiguous naming trials.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication15">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Word-Object Learning via Visual Exploration in Space (WOLVES): A Neural Process Account of Cross-Situational Word Learning</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Word-Object Learning via Visual Exploration in Space (WOLVES): A Neural Process Account of Cross-Situational Word Learning">
        </div>

        <p>Infants, children, and adults track word–object co‐occurrence across ambiguous naming situations to infer mappings. We introduce WOLVES, an implementation‐level neural process model grounded in memory and attention processes that simulates moment‐to‐moment gaze dynamics during CSWL. Fitting WOLVES to 12 published studies, we capture data supporting both associative and hypothesis‐testing accounts. WOLVES outperforms competitor models, generalizes to held‐out experiments, and elucidates developmental changes in memory constraints and real‐time gaze‐learning synchrony.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication16">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Formal theories clarify the complex: Generalizing a neural process account of the interaction of visual exploration and word learning in infancy</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Formal theories clarify the complex: Generalizing a neural process account of the interaction of visual exploration and word learning in infancy">
        </div>

        <p>Visual exploration and auditory processing interact to support object discrimination, categorization, and early word learning. To clarify their complex, multi‐timescale interactions, we generalize a formal neural process model of word learning to simulate two infant studies of label‐driven novelty preference (9–22 months). Simulations explain label effects on looking and mutual‐exclusivity responses. We discuss criteria for formal theories and their integration with empirical paradigms.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication17">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>A Contextualized BERT model for Knowledge Graph Completion</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="A Contextualized BERT model for Knowledge Graph Completion">
        </div>

        <p>Knowledge graphs (KGs) encode structured relations across domains but are often incomplete. Traditional embedding methods struggle with unseen entities; text‐based models incur high computational costs and semantic inconsistencies. We introduce CAB‐KGC, a Context‐Aware BERT for KGC that leverages contextual information from neighboring entities and relations to predict missing tail entities. CAB‐KGC eliminates the need for entity descriptions and negative sampling, reducing compute while improving Hit@1 by 5.3% on FB15k-237 and 4.88% on WN18RR.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication18">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Similarity in object properties supports cross-situational word learning: Predictions from a dynamic neural model confirmed</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Similarity in object properties supports cross-situational word learning: Predictions from a dynamic neural model confirmed">
        </div>

        <p>Context manipulations reveal that similarity in object properties can counterintuitively facilitate word learning. Using the WOLVES dynamic field model, we simulated CSWL under two conditions: ‘NEAR’ (objects metrically similar) and ‘FAR’ (objects distinct). WOLVES predicted superior learning in NEAR trials. An adult behavioral experiment confirmed this novel prediction, demonstrating that contextual similarity enhances cross‐situational word mapping.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication19">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>MuCoS: Efficient Drug–Target Discovery via Multi-Context-Aware Sampling in Knowledge Graphs</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="MuCoS: Efficient Drug–Target Discovery via Multi-Context-Aware Sampling in Knowledge Graphs">
        </div>

        <p>Accurate drug–target interaction prediction accelerates drug discovery. We frame the problem as link prediction on heterogeneous biomedical KGs integrating drugs, proteins, diseases, and pathways. Conventional KG methods rely on negative sampling and struggle with unseen pairs. We propose MuCoS, which prioritizes high-density neighbors to capture salient structural context and fuses these with BERT‐derived embeddings. MuCoS removes the need for negative sampling, reduces computational overhead, and yields up to 13% MRR improvement on KEGG50k and 6% on dedicated drug–target predictions.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication20">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>Evaluating Cumulative Spectral Gradient as a Complexity Measure</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Evaluating Cumulative Spectral Gradient as a Complexity Measure">
        </div>

        <p>Accurate estimation of dataset complexity is crucial for evaluating and comparing link-prediction models in knowledge graphs. The Cumulative Spectral Gradient (CSG) metric—derived from probabilistic divergence between classes within a spectral clustering framework—was proposed to quantify complexity, naturally scaling with class count and correlating with classification performance. We systematically evaluate CSG on multi-class tail-prediction tasks across standard benchmarks (FB15k-237, WN18RR) by varying Monte Carlo sample size (M) and nearest-neighbor count (K). Our results reveal that CSG is highly sensitive to K and exhibits weak correlation with mean reciprocal rank (MRR), challenging its stability and predictive power in link-prediction settings and motivating the development of more robust, classifier-agnostic complexity measures.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication21">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
    <div class="content-box">
      <div class="content-box-text">
        <h1>MuCo-KGC: Multi-Context-Aware Knowledge Graph Completion</h1>
        <div class="image-box">
          <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="MuCo-KGC: Multi-Context-Aware Knowledge Graph Completion">
        </div>

        <p>Knowledge graph completion (KGC) aims to predict missing entities or relations in incomplete graphs. Traditional embedding-based methods struggle with unseen entities and require negative sampling, while textual models incur high computational costs. We propose MuCo-KGC, a Multi-Context-Aware framework that leverages structural contexts from k-hop neighbor subgraphs around the head entity and query relation. MuCo-KGC eliminates the need for entity descriptions and negative sampling, significantly reducing computational overhead. Experiments on FB15k-237, WN18RR, CoDEx-S, and CoDEx-M demonstrate that MuCo-KGC outperforms state-of-the-art baselines, improving MRR by 1.63% on WN18RR, 3.77% on CoDEx-S, and 20.15% on CoDEx-M.
</p>
      </div>
    
      <div class="read-more">
        <a href="publication/publication22">Read more →</a>
      </div>
      <div class="overlay"></div>

    </div>
  
       
  
  </div>
</div>
</div>

<script>
  const scrollers = document.querySelectorAll(".scroller");

// If a user hasn't opted in for recuded motion, then we add the animation
if (!window.matchMedia("(prefers-reduced-motion: reduce)").matches) {
  addAnimation();
}

function addAnimation() {
  scrollers.forEach((scroller) => {
    // add data-animated="true" to every `.scroller` on the page
    scroller.setAttribute("data-animated", true);

    // Make an array from the elements within `.publications-content-wrapper`
    const scrollerInner = scroller.querySelector(".publications-content-wrapper");
    const scrollerContent = Array.from(scrollerInner.children);

    // For each item in the array, clone it
    // add aria-hidden to it
    // add it into the `.publications-content-wrapper`
    scrollerContent.forEach((item) => {
      const duplicatedItem = item.cloneNode(true);
      duplicatedItem.setAttribute("aria-hidden", true);
      scrollerInner.appendChild(duplicatedItem);
    });
  });
}
</script>
<footer class="lab-footer">
  <div class="footer-left">
    <h4>© Dr. Ajaz Ahmad Bhat's Lab</h4>
  </div>
  <div class="footer-right">
    <a href="/lab_website_private/contact-us" class="">Contact us</a>
    <address>
      <p class="">School of Digital Science</p>
      <p class="">2nd Floor of Academy of Brunei Studies Building, Universiti Brunei Darussalam, Jalan Tungku Link, BE1410</p>
      <p class="">Negara Brunei Darussalam</p>
    </address>
  </div>
</footer>




        <script type="text/javascript" src="/lab_website_private/assets/js/jquery-3.7.1.min.js"></script>
<script type="text/javascript" src="/lab_website_private/assets/js/functions.js"></script>
    </body>
</html>