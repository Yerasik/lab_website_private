#IMPORTANT
#when you change a slide change the data in the assets/img/publications folder
- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Learning with a network of Competing Synapses"
  reference: "#some-publication-1"
  number: "1"
  tags: ["synapses","learning"]
  authors: "Bhat A. A., Mahajan G., & Mehta A."
  journal: "PLoS ONE"
  link: "https://doi.org/10.1371/journal.pone.0025048"
  origin: "publication/publication1"
  abstract: "Competition between synapses arises in correlation-based plasticity. We propose a game-theory-inspired model in which synapses switch between weak and strong states, driven by local competition and memory of past outcomes. The framework reproduces power-law forgetting and captures motor adaptation phenomena like savings and rebound via distinct timescales."  
  methodology: "We model each synapse as a binary unit updated by parallel/sequential rules. Synaptic transition probabilities depend on neighbors' states and a memory parameter. We derive mean-field equations, identify phases via simulations, and compare system-level learning and forgetting curves to existing motor adaptation data."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Dynamics of Competitive Learning: The Role of Updates and Memory"
  reference: "#some-publication-2"
  number: "2"
  tags: ["competition","plasticity"]
  authors: "Bhat A. A. & Mehta A."
  journal: "Physical Review E"
  link: "https://doi.org/10.1103/PhysRevE.85.011134"
  origin: "publication/publication2"
  abstract: "We analyze how parallel versus sequential updating and synaptic memory affect phases of consensus and polarization in a competitive learning model. The phase diagram exhibits ordered and disordered regimes, with critical exponents matching the voter model universality class."  
  methodology: "We study a two-strategy spin-like model on a lattice, applying all combinations of parallel and sequential updates. Success rates over a memory window govern strategy updates. Monte Carlo simulations and finite-size scaling determine phase boundaries and critical behavior."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "“Connecting Experiences”: Towards a Biologically Inspired Episodic Memory for Developmental Robots"
  reference: "#some-publication-3"
  number: "3"
  tags: ["episodic-memory","robotics"]
  authors: "Bhat A. A., Mohan V., Rea F., Morasso P., & Sandini G."
  journal: "IEEE ICDL-EPIROB 2014"
  link: "https://doi.org/10.1109/DEVLRN.2014.6983007"
  origin: "publication/publication3"
  abstract: "Robots must flexibly connect context-relevant chunks of past experience to meet novel goals. We introduce a neural framework that encodes high-dimensional sensorimotor episodes into structured episodic memory and retrieves relevant sequences to simulate unexperienced actions."  
  methodology: "The model uses self-organizing maps to discretize sensory and motor inputs, linked via a hub layer. Episodes are stored as trajectories in this low-dimensional space. A cue triggers hippocampal-like recall through spreading activation and a dynamics simulates future states."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "From Object-Action to Property-Action: Learning Causally Dominant Properties through Cumulative Explorative Interactions"
  reference: "#some-publication-4"
  number: "4"
  tags: ["causal-learning","robotics"]
  authors: "Mohan V., Bhat A. A., Morasso P., & Sandini G."
  journal: "Biologically Inspired Cognitive Architectures"
  link: "https://doi.org/10.1016/j.bica.2014.11.006"
  origin: "publication/publication4"
  abstract: "We explore how robots can discover which object properties drive task outcomes by cumulatively interacting with objects varying along multiple dimensions. Through a dynamic neural field model, robots infer causally dominant properties from exploration data without supervision."  
  methodology: "A dynamic field theory-based architecture tracks instantaneous perceptual activations and integrates them across trials. Simulations and real‐robot trials show that the system correctly identifies weight or shape as the critical dimension for floating tasks."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "How iCub Learns to Imitate Use of a Tool Quickly by Recycling the Past Knowledge Learnt During Drawing"
  reference: "#some-publication-5"
  number: "5"
  tags: ["imitation","tool-use"]
  authors: "Bhat A. A. & Mohan V."
  journal: "Biomimetic and Biohybrid Systems"
  link: "https://doi.org/10.1007/978-3-319-22979-9_33"
  origin: "publication/publication5"
  abstract: "We show that the iCub humanoid can generalize motor skills by representing movements as shape primitives. After learning to draw shapes, the robot rapidly adapts to tool use tasks by recombining existing shape modules rather than learning from scratch."  
  methodology: "Motion trajectories are encoded via a passive motion paradigm into basis shapes. Tool trajectories are decomposed onto these bases. A mapping network aligns tool affordances to known shape modules, enabling quick motor command synthesis without full re-training."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Humanoid Robot Infers Archimedes' Principle: From Cumulative Exploration to Abstraction of Underlying Physical Relations and Object Affordances"
  reference: "#some-publication-6"
  number: "6"
  tags: ["affordances","cognitive-robotics"]
  authors: "Bhat A. A., Mohan V., Sandini G., & Morasso P."
  journal: "Journal of the Royal Society Interface"
  link: "https://doi.org/10.1098/rsif.2016.0310"
  origin: "publication/publication6"
  abstract: "Reenacting Aesop's Crow and Pitcher on a humanoid, we propose a neural architecture that encodes sensorimotor interactions into episodic traces and applies four learning rules (elimination, growth, uncertainty, status quo) to extract causal relations. The robot's predictions for novel objects converge to Archimedes' law."  
  methodology: "An episodic memory network stores one-shot object-water interactions. Learning rules compare predicted to recalled outcomes to adjust feature weights. Generalization is tested on unseen objects; the abstracted model matches expected fluid displacement."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Towards a Learnt Neural Body Schema for Dexterous Coordination of Action in Humanoid and Industrial Robots"
  reference: "#some-publication-7"
  number: "7"
  tags: ["body-schema","coordination"]
  authors: "Bhat A. A., Mohan V., Akkaladevi S. C., Eitzinger C., Sandini G., & Morasso P."
  journal: "Autonomous Robots"
  link: "https://doi.org/10.1007/s10514-016-9563-3"
  origin: "publication/publication7"
  abstract: "We describe a neural framework that learns a distributed body schema enabling simultaneous control of multiple limbs or tools. Forward simulations inform real-time motor plans, resolving redundancy by well-posed field computations rather than inverse kinematics."  
  methodology: "Self-organizing maps encode joint and tool configurations. A hub layer integrates modalities. Task constraints inject attractor fields. Motor commands arise from minimizing prediction error via passive motion paradigm. Validated on iCub (53 DoF) and industrial arms."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "A Dynamic Neural Field Model of Memory, Attention and Cross-Situational Word Learning"
  reference: "#some-publication-8"
  number: "8"
  tags: ["word-learning","attention"]
  authors: "Bhat A. A., Spencer J. P., & Samuelson L. K."
  journal: "Proceedings CogSci 2018"
  link: "https://mindmodeling.org/cogsci2018/papers/0048/index.html"
  origin: "publication/publication8"
  abstract: "WOLVES integrates dynamic neural fields for vision and language to model cross-situational word learning. Peaks represent sustained attention to objects and words; memory fields accumulate co-occurrence statistics. The model reproduces human looking and learning curves across 12 experiments."  
  methodology: "Eight coupled field equations evolve under local excitation and lateral inhibition. Word triggers excite word-object binding fields; gaze dynamics follow activation peaks. Co-occurrence counts update associative maps across trials. Simulations match children's preferential looking data."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Joint Goal Human-Robot Collaboration—From Remembering to Inferring"
  reference: "#some-publication-9"
  number: "9"
  tags: ["collaboration","planning"]
  authors: "Mohan V. & Bhat A. A."
  journal: "Procedia Computer Science"
  link: "https://doi.org/10.1016/j.procs.2018.01.089"
  origin: "publication/publication9"
  abstract: "We present a bio-inspired neural architecture where two robots learn internal models of their bodies and peripersonal space. Coupled simulations allow anticipation of partner actions and dynamic task allocation, enabling cooperative assembly of fuse-boxes in unstructured environments."  
  methodology: "Robots learn forward models via sensorimotor exploration. A reward-driven planner uses internal simulation to evaluate feasibility and sequence complementary actions. Real-world trials with two UR5 arms demonstrate joint key insertions and collision avoidance."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Goal-Directed Reasoning and Cooperation in Robots in Shared Workspaces: An Internal Simulation-Based Neural Framework"
  reference: "#some-publication-10"
  number: "10"
  tags: ["planning","simulation"]
  authors: "Bhat A. A. & Mohan V."
  journal: "Cognitive Computation"
  link: "https://doi.org/10.1007/s12559-018-9553-1"
  origin: "publication/publication10"
  abstract: "In an industrial assembly task, two robots share workspace to assemble fuse-boxes. We describe coupled forward models of body and peripersonal space learned via exploration. Internal simulation evaluates action-consequence pairs, driving cooperative sequences even when solo goals are unachievable."  
  methodology: "Each robot's body schema and peripersonal space are learned via self-organized map clustering. During run-time, action candidates are simulated in the forward model, scored by task reward. A shared planner sequences individual goals into cooperative behaviors."  
  acknowledgements: "blank"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Muscle-less motor synergies and actions without movements. From motor neuroscience to cognitive robotics"
  reference: "#some-publication-11"
  number: "11"
  tags: ["motor-synergies","cognitive-robotics"]
  authors: "Mohan V., Bhat A. A., & Morasso P."
  journal: "Physics of Life Reviews"
  link: "https://doi.org/10.1016/j.plrev.2018.04.005"
  origin: "publication/publication11"
  abstract: |
    Emerging trends in neurosciences provide converging evidence that cortical networks in predominantly motor areas are activated in multiple contexts related to “action” that do not cause overt movement. For complex bodies—human or embodied robots—there must be a seamless alternation between shaping motor output during action execution and simulating potential actions for feasibility and understanding. Revisiting the Equilibrium Point Hypothesis and muscle‐synergy formation, this article proposes a “plastic, configurable” internal body‐schema as a unifying principle enabling both real and imagined actions through internal simulation. The theoretical rationale is grounded in intracranial recordings, fMRI studies of action execution/imagination, tool‐use experiments, and computational robot models to show how muscleless motor synergies arise from goal‐directed body‐schema animation.
  methodology: |
    This paper synthesizes interdisciplinary findings—neurophysiological recordings, fMRI, behavioural tool‐use studies, and robotics simulations—under a computational framework. The authors formalize an internal body‐schema model and Equilibrium Point Hypothesis to generate muscleless synergies. Computational experiments on simulated robotic limbs illustrate how body‐schema animation yields both overt and covert action trajectories without direct kinematic inversion. The approach integrates forward/inverse model comparisons, dimensionality reduction of synergy patterns, and tool‐incorporation case studies.
  acknowledgements: "None declared"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "The complementarity of ‘Muscleless’ motor synergies with motor control strategies in humans and robots: Reply to Comments"
  reference: "#some-publication-12"
  number: "12"
  tags: ["motor-synergies","control"]
  authors: "Mohan V., Morasso P., & Bhat A. A."
  journal: "Physics of Life Reviews"
  link: "https://doi.org/10.1016/j.plrev.2019.11.001"
  origin: "publication/publication12"
  abstract: |
    No abstract provided.
  methodology: |
    This article is a formal reply to commentary on the original “Muscleless motor synergies” review. It clarifies theoretical points, addresses criticisms about internal model accuracy and synergy versus control distinctions, and elaborates on internal simulation constraints, but does not present new empirical methods.
  acknowledgements: "None declared"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Causal Learning by a Robot with Semantic-Episodic Memory in an Aesop's Fable Experiment"
  reference: "#some-publication-13"
  number: "13"
  tags: ["causal-learning","episodic-memory"]
  authors: "Bhat A. A. & Mohan V."
  journal: "ICLR (arXiv)"
  link: "https://arxiv.org/abs/2003.00274"
  origin: "publication/publication13"
  abstract: |
    Corvids, apes, and children solve the Crow and the Pitcher task, indicating causal understanding. To explore how agents abstract cause–effect relations from cumulative interactions, we re-enact the task on a robot equipped with a brain-guided neural model of semantic-episodic memory. Four task-agnostic learning rules compare expectations recalled from past episodes with current scenarios to extract hidden causal relations. Robot behaviors illustrate causal learning, and predictions for novel objects converge to Archimedes’ principle, independent of exploration order and object set.
  methodology: |
    The Crow and Pitcher task was implemented on an iCub robot. A neural architecture with semantic-episodic memory modules encoded object properties and past interactions. Four learning rules—discrepancy detection, semantic binding, episodic attenuation, and expectation update—were applied to compare recalled episode outputs to sensory feedback. Robot trials with objects of varying weight, shape, color, and volume tested causal inference. Behavioral outcomes were evaluated against physical principles.
  acknowledgements: "No acknowledgements provided"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Effect of Metric Variation in Object Shapes and Colours on Cross-Situational Word Learning in Adults"
  reference: "#some-publication-14"
  number: "14"
  tags: ["word-learning","variation"]
  authors: "Bhat A. A., Spencer J. P., & Samuelson L. K."
  journal: "OSF Pre-registry"
  link: "https://osf.io/rbg7m"
  origin: "publication/publication14"
  abstract: |
    Cross-situational word learning (CSWL) requires tracking word–object co-occurrence across ambiguous naming scenarios to infer correct mappings. Prior work shows eye movements reflect learning success but may be influenced by object properties. This experiment will systematically vary object shape and colour distances on each trial—‘Near’ (similar) versus ‘Far’ (distinct)—while controlling stimulus pairs. Eye-tracking and forced-choice naming tests will assess how metric variation affects real-time attention and word‐learning accuracy.
  methodology: |
    Adult participants complete CSWL trials in a within-subjects design. On each trial, two novel objects appear with a novel label; object pairs are manipulated to be similar (‘Near’) or distinct (‘Far’) in shape or colour. Eye movements are recorded to track referent selection. After training, forced-choice tests measure word–object mapping accuracy. Statistical analyses compare learning across Near vs. Far conditions and correlate gaze durations with performance.
  acknowledgements: "None declared"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Moving beyond Associative Learning and Hypothesis Testing: How Stimulus Exposure Times and Looking Behaviours Conspire in Cross-Situational Word Learning"
  reference: "#some-publication-15"
  number: "15"
  tags: ["word-learning","attention"]
  authors: "Bhat A. A., Spencer J. P., & Samuelson L. K."
  journal: "OSF Pre-registry"
  link: "https://osf.io/htd7p"
  origin: "publication/publication15"
  abstract: |
    This pre‐registered study investigates how the duration of stimulus exposure and participants’ looking behaviours jointly influence cross‐situational word learning. By manipulating exposure times and recording eye movements, we will examine contributions of associative learning versus hypothesis‐testing mechanisms across multiple ambiguous naming trials.
  methodology: |
    Adult learners complete CSWL tasks under varied stimulus exposure durations (short vs. long). Eye‐tracking captures real‐time fixations on each object during word presentation. Learning outcomes are assessed via forced‐choice tests. We fit computational models implementing associative accumulation and hypothesis‐testing algorithms to gaze and choice data to determine which processes dominate under different exposure conditions.
  acknowledgements: "None declared"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Word-Object Learning via Visual Exploration in Space (WOLVES): A Neural Process Account of Cross-Situational Word Learning"
  reference: "#some-publication-16"
  number: "16"
  tags: ["word-learning","exploration"]
  authors: "Bhat A. A., Spencer J. P., & Samuelson L. K."
  journal: "Psychological Review"
  link: "https://doi.org/10.1037/rev0000313"
  origin: "publication/publication16"
  abstract: |
    Infants, children, and adults track word–object co‐occurrence across ambiguous naming situations to infer mappings. We introduce WOLVES, an implementation‐level neural process model grounded in memory and attention processes that simulates moment‐to‐moment gaze dynamics during CSWL. Fitting WOLVES to 12 published studies, we capture data supporting both associative and hypothesis‐testing accounts. WOLVES outperforms competitor models, generalizes to held‐out experiments, and elucidates developmental changes in memory constraints and real‐time gaze‐learning synchrony.
  methodology: |
    WOLVES integrates dynamic neural fields for visual exploration, a binding map for word–object associations, and memory buffers across multiple timescales. We parameterized the model to empirical eye‐tracking and forced‐choice accuracy data from infants to adults. Bayesian optimization estimated attention and memory decay parameters. Model fits were compared to associative learning and hypothesis‐testing algorithms using cross‐validation and percent‐error metrics.
  acknowledgements: "No acknowledgements provided"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Formal theories clarify the complex: Generalizing a neural process account of the interaction of visual exploration and word learning in infancy"
  reference: "#some-publication-17"
  number: "17"
  tags: ["word-learning","neural-model"]
  authors: "Bhat A. A., Samuelson L. K., & Spencer J. P."
  journal: "Child Development"
  link: "https://doi.org/10.1111/cdev.14023"
  origin: "publication/publication17"
  abstract: |
    Visual exploration and auditory processing interact to support object discrimination, categorization, and early word learning. To clarify their complex, multi‐timescale interactions, we generalize a formal neural process model of word learning to simulate two infant studies of label‐driven novelty preference (9–22 months). Simulations explain label effects on looking and mutual‐exclusivity responses. We discuss criteria for formal theories and their integration with empirical paradigms.
  methodology: |
    The WOLVES dynamic neural process model was extended to simulate 9–22‐month‐olds’ novelty‐driven looking paradigms. Parameter settings for memory consolidation and attention dynamics were adjusted to match two empirical datasets. Model predictions of looking‐time curves and exclusivity choices were compared to published infant data. Goodness‐of‐fit was assessed via mean squared error and Akaike information criterion.
  acknowledgements: |
    Supported by the Eunice Kennedy Shriver National Institute of Child Health and Human Development (Grant HD045713).

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "A Contextualized BERT model for Knowledge Graph Completion"
  reference: "#some-publication-18"
  number: "18"
  tags: ["knowledge-graphs","bert"]
  authors: "Gul H. & Bhat A. A."
  journal: "NeurIPS Workshop (to appear)"
  link: "https://arxiv.org/abs/2412.11016"
  origin: "publication/publication18"
  abstract: |
    Knowledge graphs (KGs) encode structured relations across domains but are often incomplete. Traditional embedding methods struggle with unseen entities; text‐based models incur high computational costs and semantic inconsistencies. We introduce CAB‐KGC, a Context‐Aware BERT for KGC that leverages contextual information from neighboring entities and relations to predict missing tail entities. CAB‐KGC eliminates the need for entity descriptions and negative sampling, reducing compute while improving Hit@1 by 5.3% on FB15k-237 and 4.88% on WN18RR.
  methodology: |
    CAB‐KGC constructs head context (Hc) and relation context (Rc) by sampling k‐hop neighbors of the head entity and adjacent relation sequences. Hc and Rc are concatenated into BERT‐formatted input sequences and fine-tuned with cross‐entropy loss to predict tail entities. No negative sampling is used. Models are trained and evaluated on FB15k-237 and WN18RR, with Hit@k and MRR reported against TransE, ComplEx, and KG-BERT baselines.
  acknowledgements: "No acknowledgements provided"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Similarity in object properties supports cross-situational word learning: Predictions from a dynamic neural model confirmed"
  reference: "#some-publication-19"
  number: "19"
  tags: ["word-learning","similarity"]
  authors: "Bhat A. A., Spencer J. P., & Samuelson L. K."
  journal: "CogSci Proceedings"
  link: "https://escholarship.org/uc/item/893685t3"
  origin: "publication/publication19"
  abstract: |
    Context manipulations reveal that similarity in object properties can counterintuitively facilitate word learning. Using the WOLVES dynamic field model, we simulated CSWL under two conditions: ‘NEAR’ (objects metrically similar) and ‘FAR’ (objects distinct). WOLVES predicted superior learning in NEAR trials. An adult behavioral experiment confirmed this novel prediction, demonstrating that contextual similarity enhances cross‐situational word mapping.
  methodology: |
    Adult participants (n=40) completed a CSWL task with 48 trials. On each trial, two objects differed either minimally (NEAR) or maximally (FAR) in colour or shape and were paired with a novel word. Eye‐tracking recorded fixations during training; forced‐choice tests measured mapping accuracy. The WOLVES model was parameterized to human gaze and accuracy data. Learning rates across conditions were compared using mixed‐effects logistic regression.
  acknowledgements: "No acknowledgements provided"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "MuCoS: Efficient Drug–Target Discovery via Multi-Context-Aware Sampling in Knowledge Graphs"
  reference: "#some-publication-20"
  number: "20"
  tags: ["drug-discovery","knowledge-graphs"]
  authors: "Gul H., Naim A. G., & Bhat A. A."
  journal: "ACL BioNLP Workshop, NeurIPS 2025"
  link: "https://arxiv.org/abs/2503.08075"
  origin: "publication/publication20"
  abstract: |
    Accurate drug–target interaction prediction accelerates drug discovery. We frame the problem as link prediction on heterogeneous biomedical KGs integrating drugs, proteins, diseases, and pathways. Conventional KG methods rely on negative sampling and struggle with unseen pairs. We propose MuCoS, which prioritizes high-density neighbors to capture salient structural context and fuses these with BERT‐derived embeddings. MuCoS removes the need for negative sampling, reduces computational overhead, and yields up to 13% MRR improvement on KEGG50k and 6% on dedicated drug–target predictions.
  methodology: |
    MuCoS samples a fixed number of nearest neighbors in the KG to form multi-context subgraphs around each head–relation pair. Structural embeddings from TransE and contextual embeddings from BERT are concatenated and fed to a feed-forward network trained with cross-entropy loss. No negative samples are required. Performance is evaluated on KEGG50k using MRR and Hits@k against TransE, ComplEx-SE, and NeoDTI baselines.
  acknowledgements: "No acknowledgements provided"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "Evaluating Cumulative Spectral Gradient as a Complexity Measure"
  reference: "#some-publication-21"
  number: "21"
  tags: ["spectral-gradient","complexity"]
  authors: "Gul H., Naim A. G., & Bhat A. A."
  journal: "ICML Workshop Proceedings (PMLR 267, 2025)"
  link: "https://openreview.net/pdf?id=H0CKbqT937"
  origin: "publication/publication21"
  abstract: |
    Accurate estimation of dataset complexity is crucial for evaluating and comparing link-prediction models in knowledge graphs. The Cumulative Spectral Gradient (CSG) metric—derived from probabilistic divergence between classes within a spectral clustering framework—was proposed to quantify complexity, naturally scaling with class count and correlating with classification performance. We systematically evaluate CSG on multi-class tail-prediction tasks across standard benchmarks (FB15k-237, WN18RR) by varying Monte Carlo sample size (M) and nearest-neighbor count (K). Our results reveal that CSG is highly sensitive to K and exhibits weak correlation with mean reciprocal rank (MRR), challenging its stability and predictive power in link-prediction settings and motivating the development of more robust, classifier-agnostic complexity measures.
  methodology: |
    We compute CSG on embedding spaces generated by standard KG embedding models, treating each candidate tail entity as a separate class. By varying M (Monte Carlo samples per class) and K (number of nearest neighbors), we derive CSG values for each head–relation pair. Correlation analyses between CSG scores and link-prediction metrics (MRR, Hits@k) are conducted across FB15k-237, WN18RR, and additional benchmarks. Sensitivity analyses assess the impact of parameter choices on CSG’s stability and scalability.
  acknowledgements: "No acknowledgements provided"

- image: https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg
  title: "MuCo-KGC: Multi-Context-Aware Knowledge Graph Completion"
  reference: "#some-publication-22"
  number: "22"
  tags: ["knowledge-graphs","completion"]
  authors: "Gul H., Naim A. G., & Bhat A. A."
  journal: "arXiv preprint / PAKDD DSFA Special Session"
  link: "https://arxiv.org/abs/2503.03091"
  origin: "publication/publication22"
  abstract: |
    Knowledge graph completion (KGC) aims to predict missing entities or relations in incomplete graphs. Traditional embedding-based methods struggle with unseen entities and require negative sampling, while textual models incur high computational costs. We propose MuCo-KGC, a Multi-Context-Aware framework that leverages structural contexts from k-hop neighbor subgraphs around the head entity and query relation. MuCo-KGC eliminates the need for entity descriptions and negative sampling, significantly reducing computational overhead. Experiments on FB15k-237, WN18RR, CoDEx-S, and CoDEx-M demonstrate that MuCo-KGC outperforms state-of-the-art baselines, improving MRR by 1.63% on WN18RR, 3.77% on CoDEx-S, and 20.15% on CoDEx-M.
  methodology: |
    MuCo-KGC samples fixed-size k-hop neighbor subgraphs to extract head context (neighbor entities) and relation context (adjacent relation sequences). These contexts are formatted into BERT-style input sequences and concatenated before being fine-tuned with cross-entropy loss to predict tail entities without negative sampling. The model is evaluated against TransE, ComplEx, and KG-BERT baselines using MRR and Hits@k metrics on FB15k-237, WN18RR, CoDEx-S, and CoDEx-M.
  acknowledgements: "No acknowledgements provided"

